{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0\n",
       " 0.0  0.0  0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [\n",
    "    1 2 3\n",
    "    3 2 6\n",
    "    7 8 9\n",
    "]\n",
    "\n",
    "size(x)\n",
    "\n",
    "z = zeros(Float64,size(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OperationNode"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "abstract type Node end\n",
    "\n",
    "struct InputNode <: Node\n",
    "    value::Matrix{Float64}\n",
    "    grad::Matrix{Float64}\n",
    "end\n",
    "\n",
    "struct OperationNode <: Node\n",
    "    op::Function\n",
    "    inputs::Vector{Node}\n",
    "    value::Matrix{Float64}\n",
    "    grad::Matrix{Float64}\n",
    "end\n",
    "\n",
    "function InputNode(value::Matrix{Float64})\n",
    "    InputNode(value, zeros(size(value)))\n",
    "end\n",
    "\n",
    "function OperationNode(op::Function, inputs::Vector{Node})\n",
    "    OperationNode(op, inputs, zeros(size(inputs[1].value)), zeros(size(inputs[1].value)))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InputNode([1.0 2.0 3.0; 3.0 2.0 6.0; 7.0 8.0 9.0], [0.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_d = [\n",
    "    1 2 3\n",
    "    3 2 6\n",
    "    7 8 9.0\n",
    "]\n",
    "x = InputNode(x_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval (generic function with 3 methods)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function add(x::Node, y::Node)\n",
    "    return OperationNode((a, b) -> a .+ b, [x, y])\n",
    "end\n",
    "\n",
    "function mul(x::Node, y::Node)\n",
    "    return OperationNode((a, b) -> a * b, [x, y])\n",
    "end\n",
    "\n",
    "function eval(node::InputNode)\n",
    "    return node.value\n",
    "end\n",
    "\n",
    "function eval(node::OperationNode)\n",
    "    input_values = map(eval, node.inputs)\n",
    "    return node.op(input_values...)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNCell"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "struct RNNCell\n",
    "    Wxh::Matrix{Float64}  # Wagi dla wejścia\n",
    "    Whh::Matrix{Float64}  # Wagi dla stanu ukrytego\n",
    "    Why::Matrix{Float64}  # Wagi dla wyjścia\n",
    "    bh::Vector{Float64}   # Bias dla stanu ukrytego\n",
    "    by::Vector{Float64}   # Bias dla wyjścia\n",
    "end\n",
    "\n",
    "function RNNCell(input_dim::Int, hidden_dim::Int, output_dim::Int)\n",
    "    RNNCell(randn(hidden_dim, input_dim), randn(hidden_dim, hidden_dim),\n",
    "            randn(output_dim, hidden_dim), randn(hidden_dim), randn(output_dim))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rnn_forward (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function rnn_forward(cell::RNNCell, inputs::Vector{InputNode})\n",
    "    h = zeros(size(cell.Whh))  # Początkowy stan ukryty (kolumna)\n",
    "    outputs = Vector{Matrix{Float64}}(undef, length(inputs))\n",
    "    states = Vector{Matrix{Float64}}(undef, length(inputs))\n",
    "\n",
    "    for t in 1:length(inputs)\n",
    "        h = tanh.(cell.Wxh * inputs[t].value .+ cell.Whh * h .+ cell.bh)\n",
    "        y = cell.Why * h .+ cell.by\n",
    "        states[t] = h\n",
    "        outputs[t] = y\n",
    "    end\n",
    "\n",
    "    return outputs, states\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rnn_backward (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function rnn_backward(cell::RNNCell, inputs::Vector{InputNode}, states::Vector{Matrix{Float64}}, outputs::Vector{Matrix{Float64}}, targets::Vector{Matrix{Float64}}, learning_rate::Float64)\n",
    "    dWxh, dWhh, dWhy = zeros(cell.Wxh), zeros(cell.Whh), zeros(cell.Why)\n",
    "    dbh, dby = zeros(cell.bh), zeros(cell.by)\n",
    "    dh_next = zeros(size(states[1]))\n",
    "\n",
    "    for t in length(inputs):-1:1\n",
    "        dy = outputs[t] - targets[t]\n",
    "        dWhy += dy * states[t]'\n",
    "        dby += dy\n",
    "        dh = (cell.Why' * dy) + dh_next\n",
    "        dh_raw = (1 .- states[t].^2) .* dh  # Gradient through tanh\n",
    "        dbh += dh_raw\n",
    "        dWxh += dh_raw * inputs[t].value'\n",
    "        dWhh += dh_raw * (t > 1 ? states[t-1] : zeros(size(states[1])))'\n",
    "        dh_next = cell.Whh' * dh_raw\n",
    "    end\n",
    "\n",
    "    # Update weights\n",
    "    cell.Wxh -= learning_rate * dWxh\n",
    "    cell.Whh -= learning_rate * dWhh\n",
    "    cell.Why -= learning_rate * dWhy\n",
    "    cell.bh -= learning_rate * dbh\n",
    "    cell.by -= learning_rate * dby\n",
    "\n",
    "    return cell\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "straken\n"
     ]
    },
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching zeros(::Matrix{Float64})\n\nClosest candidates are:\n  zeros(!Matched::Union{Integer, AbstractUnitRange}...)\n   @ Base array.jl:631\n  zeros(!Matched::Type{T}, !Matched::Tuple{}) where T\n   @ Base array.jl:640\n  zeros(!Matched::Type{T}, !Matched::Tuple{Vararg{Integer, N}}) where {T, N}\n   @ Base array.jl:635\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching zeros(::Matrix{Float64})\n",
      "\n",
      "Closest candidates are:\n",
      "  zeros(!Matched::Union{Integer, AbstractUnitRange}...)\n",
      "   @ Base array.jl:631\n",
      "  zeros(!Matched::Type{T}, !Matched::Tuple{}) where T\n",
      "   @ Base array.jl:640\n",
      "  zeros(!Matched::Type{T}, !Matched::Tuple{Vararg{Integer, N}}) where {T, N}\n",
      "   @ Base array.jl:635\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] rnn_backward(cell::RNNCell, inputs::Vector{InputNode}, states::Vector{Matrix{Float64}}, outputs::Vector{Matrix{Float64}}, targets::Vector{Matrix{Float64}}, learning_rate::Float64)\n",
      "   @ Main c:\\Users\\Kiczu\\Desktop\\AutoDiff\\custom\\test_new.ipynb:2\n",
      " [2] top-level scope\n",
      "   @ c:\\Users\\Kiczu\\Desktop\\AutoDiff\\custom\\test_new.ipynb:19"
     ]
    }
   ],
   "source": [
    "# Parametry\n",
    "input_dim = 3\n",
    "hidden_dim = 5\n",
    "output_dim = 2\n",
    "seq_length = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "cell = RNNCell(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "\n",
    "inputs = [InputNode(rand(input_dim, 1)) for _ in 1:seq_length]\n",
    "targets = [rand(output_dim, 1) for _ in 1:seq_length]\n",
    "\n",
    "\n",
    "for epoch in 1:100\n",
    "    println(\"Epoch: $epoch\")\n",
    "    outputs, states = rnn_forward(cell, inputs)\n",
    "    println(\"straken\")\n",
    "    cell = rnn_backward(cell, inputs, states, outputs, targets, learning_rate)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: no method matching zeros(::Matrix{Float64})\n\nClosest candidates are:\n  zeros(!Matched::Union{Integer, AbstractUnitRange}...)\n   @ Base array.jl:631\n  zeros(!Matched::Type{T}, !Matched::Tuple{}) where T\n   @ Base array.jl:640\n  zeros(!Matched::Type{T}, !Matched::Tuple{Vararg{Integer, N}}) where {T, N}\n   @ Base array.jl:635\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching zeros(::Matrix{Float64})\n",
      "\n",
      "Closest candidates are:\n",
      "  zeros(!Matched::Union{Integer, AbstractUnitRange}...)\n",
      "   @ Base array.jl:631\n",
      "  zeros(!Matched::Type{T}, !Matched::Tuple{}) where T\n",
      "   @ Base array.jl:640\n",
      "  zeros(!Matched::Type{T}, !Matched::Tuple{Vararg{Integer, N}}) where {T, N}\n",
      "   @ Base array.jl:635\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] rnn_backward(cell::RNNCell, inputs::Vector{InputNode}, states::Vector{Matrix{Float64}}, outputs::Vector{Matrix{Float64}}, targets::Vector{Matrix{Float64}}, learning_rate::Float64)\n",
      "   @ Main c:\\Users\\Kiczu\\Desktop\\AutoDiff\\custom\\test_new.ipynb:2\n",
      " [2] top-level scope\n",
      "   @ c:\\Users\\Kiczu\\Desktop\\AutoDiff\\custom\\test_new.ipynb:18"
     ]
    }
   ],
   "source": [
    "# Parametry\n",
    "input_dim = 3\n",
    "hidden_dim = 5\n",
    "output_dim = 2\n",
    "seq_length = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Tworzymy RNN\n",
    "cell = RNNCell(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Generujemy przykładowe dane wejściowe i wyjściowe\n",
    "inputs = [InputNode(rand(input_dim, 1)) for _ in 1:seq_length]\n",
    "targets = [rand(output_dim, 1) for _ in 1:seq_length]\n",
    "\n",
    "# Trenujemy RNN przez kilka epok\n",
    "for epoch in 1:100\n",
    "    outputs, states = rnn_forward(cell, inputs)\n",
    "    cell = rnn_backward(cell, inputs, states, outputs, targets, learning_rate)\n",
    "end\n",
    "\n",
    "# Wyświetlamy wyniki\n",
    "println(\"Trained RNN output: \", outputs[end])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
