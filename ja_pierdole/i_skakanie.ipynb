{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "net2 (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "include(\"graph_ops.jl\")\n",
    "using LinearAlgebra\n",
    "\n",
    "function dense(w, b, x, activation) return activation(w * x .+ b) end\n",
    "function dense(w, x, activation) return activation(w * x) end\n",
    "function dense(w, x) return w * x end\n",
    "\n",
    "function mean_squared_loss(y, ŷ)\n",
    "    return ConstantNode(0.5) .* ((y .- ŷ) .^ ConstantNode(2))\n",
    "end\n",
    "\n",
    "function net(x, wh, wo, y)\n",
    "    x̂ = dense(wh, x, tanh)\n",
    "    ŷ = dense(wo, x̂)\n",
    "    E = mean_squared_loss(y, ŷ)\n",
    "\n",
    "    return topological_sort(E), ŷ\n",
    "end\n",
    "\n",
    "function net2(x, wh, bias, wo, y)\n",
    "    x̂ = dense(wh, bias, x, tanh)\n",
    "    ŷ = dense(wo, x̂)\n",
    "    E = mean_squared_loss(y, ŷ)\n",
    "\n",
    "    return topological_sort(E), ŷ\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "MethodError",
     "evalue": "MethodError: Cannot `convert` an object of type \n  Int64 to an object of type \n  AbstractVecOrMat\n\nClosest candidates are:\n  convert(::Type{T}, !Matched::T) where T\n   @ Base Base.jl:84\n  convert(::Type{T}, !Matched::T) where T<:AbstractArray\n   @ Base abstractarray.jl:16\n  convert(::Type{T}, !Matched::LinearAlgebra.AbstractQ) where T<:AbstractArray\n   @ LinearAlgebra C:\\Users\\Kiczu\\.julia\\juliaup\\julia-1.10.1+0.x64.w64.mingw32\\share\\julia\\stdlib\\v1.10\\LinearAlgebra\\src\\abstractq.jl:45\n  ...\n",
     "output_type": "error",
     "traceback": [
      "MethodError: Cannot `convert` an object of type \n",
      "  Int64 to an object of type \n",
      "  AbstractVecOrMat\n",
      "\n",
      "Closest candidates are:\n",
      "  convert(::Type{T}, !Matched::T) where T\n",
      "   @ Base Base.jl:84\n",
      "  convert(::Type{T}, !Matched::T) where T<:AbstractArray\n",
      "   @ Base abstractarray.jl:16\n",
      "  convert(::Type{T}, !Matched::LinearAlgebra.AbstractQ) where T<:AbstractArray\n",
      "   @ LinearAlgebra C:\\Users\\Kiczu\\.julia\\juliaup\\julia-1.10.1+0.x64.w64.mingw32\\share\\julia\\stdlib\\v1.10\\LinearAlgebra\\src\\abstractq.jl:45\n",
      "  ...\n",
      "\n",
      "\n",
      "Stacktrace:\n",
      " [1] VariableNode(output::Matrix{Float64}; name::String)\n",
      "   @ Main c:\\Users\\Kiczu\\Desktop\\AutoDiff\\ja_pierdole\\nody.jl:26\n",
      " [2] top-level scope\n",
      "   @ c:\\Users\\Kiczu\\Desktop\\AutoDiff\\ja_pierdole\\i_skakanie.ipynb:1"
     ]
    }
   ],
   "source": [
    "Wh  = VariableNode(randn(10,1))\n",
    "Wh2  = VariableNode(randn(1,10))\n",
    "Wo  = VariableNode(randn(1,10))\n",
    "bias = VariableNode(randn(10,1))\n",
    "x = InputNode([4.434])\n",
    "y = InputNode([0.064])\n",
    "losses = Float64[]\n",
    "\n",
    "\n",
    "\n",
    "graph, target = net2(x, Wh,bias, Wo, y)\n",
    "# graph, target = net2(x, Wh,Wh2, Wo, y)\n",
    "\n",
    "init_nodes!(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71-element Vector{Tuple{Vector{Float64}, Vector{Float64}}}:\n",
       " ([0.0], [0.0])\n",
       " ([0.1], [0.09983341664682815])\n",
       " ([0.2], [0.19866933079506122])\n",
       " ([0.3], [0.29552020666133955])\n",
       " ([0.4], [0.3894183423086505])\n",
       " ([0.5], [0.479425538604203])\n",
       " ([0.6], [0.5646424733950354])\n",
       " ([0.7], [0.644217687237691])\n",
       " ([0.8], [0.7173560908995228])\n",
       " ([0.9], [0.7833269096274834])\n",
       " ⋮\n",
       " ([6.2], [-0.0830894028174964])\n",
       " ([6.3], [0.016813900484349713])\n",
       " ([6.4], [0.11654920485049364])\n",
       " ([6.5], [0.21511998808781552])\n",
       " ([6.6], [0.31154136351337786])\n",
       " ([6.7], [0.4048499206165983])\n",
       " ([6.8], [0.49411335113860816])\n",
       " ([6.9], [0.5784397643882002])\n",
       " ([7.0], [0.6569865987187891])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base: sin\n",
    "data = [([i], [sin(i)]) for i in 0:0.1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `Wh` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `Wh` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\Kiczu\\Desktop\\AutoDiff\\ja_pierdole\\i_skakanie.ipynb:5"
     ]
    }
   ],
   "source": [
    "n_epochs = 100\n",
    "lr = 0.01\n",
    "data_size = length(data)\n",
    "losses = Float64[]\n",
    "Wh_acc_gradient = zeros(size(Wh.output))\n",
    "bias_acc_gradient = zeros(size(bias.output))\n",
    "Wo_acc_gradient = zeros(size(Wo.output))\n",
    "\n",
    "@time for epoch in 1:n_epochs\n",
    "    fill!(Wh_acc_gradient, 0)\n",
    "    fill!(Wo_acc_gradient, 0)\n",
    "    loss_in_epoch = 0\n",
    "    for (x_, y_) in data\n",
    "        x.output = x_\n",
    "        y.output = y_\n",
    "        currentloss = forward!(graph)\n",
    "        backward!(graph)\n",
    "        loss_in_epoch += first(currentloss)\n",
    "    end\n",
    "    Wh_acc_gradient .+= Wh.gradient\n",
    "    bias_acc_gradient .+= bias.gradient\n",
    "    Wo_acc_gradient .+= Wo.gradient\n",
    "    Wh.output .-= lr*(Wh_acc_gradient ./ data_size)\n",
    "    bias_acc_gradient .-= lr*(bias_acc_gradient ./ data_size)\n",
    "    Wo.output .-= lr*(Wo_acc_gradient ./ data_size)\n",
    "    reset!(graph)\n",
    "    println(\"Current loss: \", loss_in_epoch/data_size)\n",
    "    push!(losses, first(loss_in_epoch/data_size))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "701-element Vector{Float64}:\n",
       " NaN\n",
       " NaN\n",
       " NaN\n",
       "   9.72935070177e-312\n",
       " NaN\n",
       "   6.25988759086e-313\n",
       " NaN\n",
       "   9.72935070233e-312\n",
       " NaN\n",
       "   2.6423802457690676e-308\n",
       "   ⋮\n",
       "   9.390865887e-315\n",
       "   0.0\n",
       "   1.23092333968e-312\n",
       "   9.72102669958e-312\n",
       "   9.72102680567e-312\n",
       "   9.72102685721e-312\n",
       "   1.40068300296e-312\n",
       "   9.72102669958e-312\n",
       "   9.721026805826e-312"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import Base: sin\n",
    "data_dense_x = 0:0.1:7\n",
    "data_dense_y = sin.(data_dense_x)\n",
    "\n",
    "using Plots\n",
    "xx = 0:0.01:7\n",
    "yy = Vector{Float64}(undef, length(xx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: `x` not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: `x` not defined\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\Kiczu\\Desktop\\AutoDiff\\ja_pierdole\\i_skakanie.ipynb:4"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for i in 1:length(xx)\n",
    "    yy[i] = predict!([xx[i]], x,target, graph)[1]\n",
    "end\n",
    "\n",
    "plot(data_dense_x, data_dense_y, label=\"sin(x)\")\n",
    "plot!(xx, yy, label=\"NN approximation\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.1",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
